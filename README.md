# ğŸ“š Knowledge Transfer (KT) Project

A robust Knowledge Transfer (KT) system designed to streamline the transition of undocumented and implicit knowledge across teams using AI-powered techniques. This solution ensures continuity, accuracy, and ease of onboarding through automated parsing, semantic search, Q&A, and summarization.

---

## ğŸš€ Project Highlights

- âœ… **Multi-format Ingestion**: Supports Word, PDF, Excel, PowerPoint, and text files.
- ğŸ” **Semantic Search**: Find answers even when phrased differently using vector-based retrieval.
- ğŸ¤– **LLM-Powered Q&A**: Uses GPT-based models to answer questions from the indexed knowledge base.
- ğŸ“Š **Tiered Chunking**: Implements hierarchical chunking (Tier 1 & Tier 2) for better context preservation.
- ğŸ§  **Few-shot Prompting**: Guides the model with custom examples to reduce hallucinations.
- ğŸ’¾ **Document-level Metadata**: Tracks source, author, and context for every chunk.
- ğŸ›¡ï¸ **RAG (Retrieval-Augmented Generation)**: Ensures responses are grounded in actual indexed content.
- ğŸ§ª **Validation Metrics**: Measures hallucination rate, token usage, and retrieval accuracy.

---

## ğŸ—‚ï¸ Folder Structure
KT-Project/
â”‚
â”œâ”€â”€ ingestion/ # Parsing and pre-processing scripts
â”‚ â”œâ”€â”€ extract_pdf_text.py
â”‚ â”œâ”€â”€ extract_docx_text.py
â”‚ â””â”€â”€ extract_pptx_text.py
â”‚
â”œâ”€â”€ indexing/ # Tiered chunking and vector embedding
â”‚ â”œâ”€â”€ tier1_chunker.py
â”‚ â”œâ”€â”€ tier2_chunker.py
â”‚ â””â”€â”€ vector_store.py
â”‚
â”œâ”€â”€ qa_engine/ # LLM-powered Q&A system
â”‚ â”œâ”€â”€ rag_pipeline.py
â”‚ â”œâ”€â”€ prompt_templates.py
â”‚ â””â”€â”€ validate_response.py
â”‚
â”œâ”€â”€ streamlit_app/ # Frontend interface
â”‚ â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/ # Sample documents
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy
Edit

---

## âš™ï¸ Setup Instructions

1. **Clone the repo**
   ```bash
   git clone https://github.com/your-repo/kt-project.git
   cd kt-project
Create and activate virtual environment

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Run the Streamlit App

bash
Copy
Edit
cd streamlit_app
streamlit run app.py
ğŸ”§ Tech Stack
Python â€“ Core scripting

Streamlit â€“ Frontend interface

LangChain / LlamaIndex â€“ RAG & retrieval logic

OpenAI GPT-4 / Gemini / Claude â€“ LLM integrations

FAISS / Weaviate / Astra DB â€“ Vector search

Azure Blob / GCS / Local FS â€“ File storage

ğŸ“ˆ Evaluation Metrics
Metric	Description
Hallucination Rate	% of answers not found in original docs
Retrieval Accuracy	% of correct chunk matches
Token Usage	Average input/output tokens per query
Latency	Time taken per complete response cycle

ğŸ‘¨â€ğŸ’» Use Case Scenarios
ğŸ”„ Project Handover

ğŸ§‘â€ğŸ« Employee Onboarding

ğŸ“š Document Understanding

ğŸ§  Long-Term Knowledge Preservation

ğŸ“ Future Improvements
 Fine-tune LLM on internal domain knowledge

 Add feedback loop to train on user corrections

 Integrate Slack/Teams for inline Q&A

 Multi-language support (Hindi, Tamil, etc.)

ğŸ™Œ Acknowledgements
Special thanks to all contributors, knowledge holders, and AI platforms (OpenAI, Hugging Face, etc.) that made this project possible.



